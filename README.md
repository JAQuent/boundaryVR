README
================

This README provides a quick overview of what is to be found in this repository. 

Collaborators: Joern Alexander Quent, Rik Henson & Aya Ben-Yakov
Status: __stopped__
Reason: No boundary effect could be found. 

# Aim of this project
This project was set-out to explore which factors influence the experience of spatial boundaries with regard how they affect memory. A previous study (Horner et al., 2016) let participants navigate through a series of virtual rooms. In each room they encountered two images each showing an object. A subsequent memory test revealed that participants were better at remembering which object preceded or succeeded a cue object if both cue and target were presented in the same (within a boundary) as compared to a different room (across a boundary). 

In our experiments, we wanted to find out which characteristics of spatial boundaries (e.g. prediction error, perceptual changes, uncertainty or novelty) are crucial for the effect observed by Horner et al. (2016). To do this we created so called O rooms (i.e. open plane room) and M rooms (because of the shape). A video showing the difference between O-rooms and M-rooms can be found [here](https://vimeo.com/532276947).

# Files

- ***chapter_boundaryVR.docx*** & ***chapter_boundaryVR.Rmd*** Files that create a version of Quent's thesis chapter with some deviations as it was only used to create the result section. 
- ***notebook.md***, ***notebook.Rmd*** & ***notebook_files*** The notebook was regularly updated over the course of the project and a contains a more detailed description on how the project developed and which analyses we ran than for instance the chapter does. 

# Folders and their content

- ***analysis*** contains files for concerning the analysis. This folder contains a separate README file.  
- ***BNA2021_poster*** contains file for the poster that was presented @ BNA2021. 
- ***data***    contains the data for Exp 1, Exp 2 and Exp 3 and from Horner et al. (2016). Depending on the version of the experiment, this includes the debrief questionnaire, the memory task, the initial speed test for the browser and the response while the participants watched the video. Only data from the memory experiment was formally analysed. Some of the folders also contain testData or dataChecks, which were generated by completing the task ourselves to check for errors. 
- ***experiments*** contains the experimental files (for Exp 1 Batch 3, Exp2 and Exp 3) and files that used to create the experiment. Note that the scripts can only be used if the videos are downloaded (see below). These folders do also __not__ contain the unity3d project that were used to create the experiments. Those can also be found below. 
- ***figures*** contains the figures that was used in Quent's thesis. 

# Extra material to download

There are several files that are too large to upload to GitHub. These files are hosted on [OSF](https://osf.io/etx2a/). 

___Note if you want to use the files below, please contact alexander.quent AT rub.de or aya.benyakov AT mail.huji.ac.il for prior consultation___.

Experiments that can be run on JATOS:
- [Experiment 1 Batch 3](https://osf.io/2r4dm/download)
- [Experiment 2](https://osf.io/ca953/download)
- [Experiment 3](https://osf.io/3fb79/download)

Unity projects (not documented):
- [Experiment 1](https://osf.io/7rvs2/download)
- [Experiment 2](https://osf.io/qp3uk/download)
- [Experiment 3](https://osf.io/4vd92/download)

Build version for unity projects:
- [Experiment 3](https://osf.io/cdxqr/download) In order to run, the .exe in that folder need to be started. Note the videos can be started by pressing __Space__. 